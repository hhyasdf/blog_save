---
 title: Linux-kernel-memory-management
date: 2017-12-31
tags: 
	- OS 
	- Linux kernel
---

看完一部分ULK（深入理解linux内核），总结一下linux内核（32位）的内存管理机制，包括内核空间（内核态页框管理）的内存管理和进程空间（用户态）中的内存管理。（还没看到页框回收，先写一部分）

*************************************

### Part 1 : 内存寻址###

x86微处理器对于寻址的硬件支持包括两部分：分段和分页。**逻辑地址通过MMU中的分段单元转换成线性地址，再通过（MMU）中的分页单元转换成物理地址**，从而对物理RAM进行寻址。在SMP系统中，因为在RAM芯片上的读或写操作必须串行地执行，而多个CPU共享同一内存，因此一种所谓的**内存仲裁器（memory arbiter）**的硬件电路插在总线和每个RAM芯片之间。其作用是如果某个RAM空闲，就准予一个CPU访问，如果该芯片忙于为另一个处理器提出的请求服务，就延迟这个CPU的访问。即使在单处理器上也使用内存仲裁器（用来平衡DMA控制器和CPU的并发操作）。

在进一步了解分段和分页机制之前一定要记住：**分段和分页都是硬件支持**。内核实现在这些支持之上。

<!-- more -->

#### 分段 ####

x86中使用Seg：Offset形式的逻辑地址来进行内存操作，其中Seg表示段标识符，其内容为存放在段寄存器（cs代码段寄存器、ss栈段寄存器、ds数据段寄存器、es、fs和gs）中的16位长的段选择符（子），而Offset表示段内相对地址的偏移量。段选择子包括一个13位的索引号、1位的表指示器TI，2位的请求者特权级RPL。其中cs寄存器还有一个很重要的功能，它的RPL字段用以指明CPU的当前特权级（Current Privilege Level， CPL）。值为0代表最高优先级，而值为3代表最低优先级。linux只用到了0级（内核态）和3级（用户态）。

> ps: x86汇编中每条指令默认使用对应的段寄存器（比如说jmp默认cs），可以用段前缀改变使用的段寄存器，

当翻译逻辑地址时，硬件会先检查段选择符TI字段，以决定段描述符保存在哪个描述符表中，然后结合段寄存器中的索引号（乘以8）和GDT（全局描述符表，存放在 gdtr 寄存器中，全局只有一个）或LDT（局部描述符表，存放在 ldtr 寄存器中，可以由每个进程创建）的起始地址相加获得相应的段描述符，每个段描述符长8字节，其中包含了一个32位的包含对应段的首字节 Base 字段，再结合 Base 字段和逻辑地址中的 Offset 算出线性地址。

段描述符中有一个2位长的 DPL 字段，用于限制对这个段的存取，DPL 设为0时只有 CPL 为0时才能访问，DPL 设为3的段对于任何CPL值都是可以访问的。

每当一个段选择符被装入段寄存器时，相应的段描述符就由内存装入到对应的非编程CPU寄存器。从那时起，针对那个段的的逻辑地址转换就可以不访问主存中的GDT或LDT，处理器只需直接引用存放段描述符的CPU寄存器即可。仅当段寄存器的内容改变时，才有必要访问GDT或LDT。

GDT的第一项总是设为0。这就确保空段选择符的逻辑地址会被认为是无效的，因此引起一个处理器异常。能够保存在GDT中的段描述符的最大数目是8191,即 $ 2^{13} - 1 $。

由于分段和分页在某种程度上有点多余，因为它们都可以划分进程的物理地址空间：分段可以给每一个进程分配不同的线性地址空间，而分页可以把同一线性地址空间映射到不同的物理地址空间。所以linux以非常有限的方式使用分段。无论是对于内核的cs和ds还是用户的cs还是ds，其段描述符中的Base字段都为0x00000000，也就是说所有进程都共享同一组线性地址，并且在linux下的逻辑地址和线性地址是一致的。相应的段选择符由宏 \_\_USER_CS、\_\_USER\_DS、\_\_KERNEL\_CS和\_\_KERNEL\_DS 分别定义。然而linux仍需要使用cs段选择符中的CPL（也就是RPL字段）来反映进程是在用户态还是内核态。只要当前特权级被改变，一些段寄存器必须相应的更新。

对于linux，单处理器系统中只有一个GDT，而在多处理器系统中每个CPU对应一个GDT。所有的GDT都存放在 cpu\_gdt\_table 数组中，而所有GDT的地址和它们的大小（当初始化gdtr寄存器时使用）被存放在 cpu\_gdt\_descr 数组中（两个数组都是每CPU变量）。

GDT中包括18个段描述符和14个空的。其中包括一个任务状态段（TSS）描述符，每个处理器有一个。每个TSS相应的线性地址空间都是内核数据段相应地址空间的一个小子集。所有的任务状态段都顺序地存放在 init\_tss 数组（每CPU变量）中。第n个CPU的TSS描述符的 Base 字段指向 init\_tss 数组的第n个元素。TSS段描述符的DPL字段置0。

如前所述，系统的每个CPU都有一个GDT副本，除少数情况以外，所有GDT的副本都存放相同的表项。首先，每个处理器都有它自己的TSS段，因此其对应的GDT项不同。其次，GDT中只有少数项可能依赖于CPU正在执行的进程（LDT和TLS段描述符）。最后，在某些情况下，处理器可能临时修改GDT副本里的某个项；例如，当调用APM的BIOS例程时会发生这种情况。

大多数用户态下的linux程序不使用局部描述符表，这样内核就定义了一个缺省的LDT供大多数进程共享。缺省的LDT存放在 default_ldt 数组中。在某些情况下，进程仍需要创建自己的局部描述符表。modify\_ldt() 系统调用允许进程创建自己的局部描述符表，它会相应地修改该CPU中GDT副本的LDT表项。



#### 分页 ####

分页单元把线性地址转换成物理地址。线性地址空间被分成以固定长度为单位的组，称为页（page），页内部连续的线性地址被映射到连续的物理地址中。RAM也被以相同的固定长度分为若干个页框（page frame）。页框与页的大小一致。我们应该把页理解为一个数据块，它可以存放在任何页框或者磁盘中。linux中一个页一般为4KB大小。

把线性地址映射到物理地址的数据结构称为页表（page table）。页表存放在主存中，并在启用分页单元之前必须由内核对页表进行适当的初始化。x86处理器中通过设置 cr0 处理器的 PG 标志来开启分页支持。当 PG=0 时，线性地址就被解释为物理地址。

一个线性地址被硬件划分为多个部分（32位不用PAE两级页表就够了），页表的组织也取决于硬件对线性地址的划分方式。一张页表大小和页的大小一致，一般为4KB。为了通过只为进程实际使用的那些虚拟内存空间请求页表来减少内存的使用量，linux采用多级页表的机制（64位是3~4级页表，用到了48或57位线性地址，页表级数不包括页）。线性地址的每个部分（除了最后一部分表示在一个页内的偏移量，这一部分的长度总是与页的大小的对数相同，一般为12位，其他部分长度为对应页表中页表项数量的对数）都表示对应级页表中的一个页表项，因为每个页框有4KB的容量，它的物理地址必须是4096的倍数，因此物理地址的最低12位总是为0，而页表项的 Field 字段存储了对应页（表）的地址的高位，由此可以通过页表项的 Field 字段算出下级页（表）的物理地址。而 Field 字段的长度也限制了能使用的物理RAM的大小。一般（32位PC） Filed 字段为20位，此时页表项长度为32位，每张页表有1024个页表项，对应支持4GB RAM。

最高级页表（只有一张，也被称为页目录）的地址存放在控制寄存器 cr3 中。

从Pentium模型开始，80x86处理器引入了扩展分页（extended paging），它允许页框大小为4MB而不是4KB（此时线性地址的最后两部分合并为页内偏移，此时如果 Filed 字段为20，那么只有高10位是有意义的，因为物理地址以4MB对齐），扩展分页用于把大段连续的线性地址转换成相应的物理地址，在这种情况下，内核可以不用最低级的页表进行地址转换，从而节省内存减少页表数目并保留TLB项。通过设置高级页表的 Page Size 标志启用扩展分页功能。通过设置 cr4 寄存器的 PSE 标志能使扩展分页与常规分页共存。

与页和页表相关的特权级只有两个，由页表项中 User/Supervisor 标志所控制。若这个标志为0，只有当CPL小于3时（对于linux讲为内核态）才能对页寻址；若该标志为1，则总能对页寻址。

x86物理地址扩展（PAE）机制：通过设置 cr4 控制寄存器中的 PAE 标志激活该功能。通过将页表项的 Filed 字段从20位扩展到24位可以支持最大64GB RAM，页表项大小从32变为64，一个页表包含的页表项数目也变成了512.并且 cr3 指向一个PDPT页目录指针表 4*64bit。在32位PAE下，存在的主要问题是线性地址仍然是32位长，这就迫使内核编程人员只有用同一线性地址映射不同的RAM区才能使用容量高达64GB的RAM，并且用户态下运行的进程不能使用（不是地址，页框总和）大于4GB的物理地址空间，因为只用内核能够修改进程的页表。

处理器的 cr0 寄存器的CD标志位来启用或禁用高速缓存电路。这个寄存器中的 NW 标志指明高速缓存是使用通写还是回写策略。Pentium处理器高速缓存的另一个有趣的特点是，让操作系统把不同的高速缓存管理策略与每一个页框相关联。为此，每一个页表项都包含两个标志；PCD（Page Cache Disable）标志指明当访问包含在这个页框中的数据时，高速缓存功能必须被启用还是禁用。PWT（page Write-Through）标志指明当把数据写到页框时，必须使用的策略是回写还是通写。**linux清除了所有页表项的PCD和PWD标志；结果是：对于所有的页框都启用高速缓存，对于写操作总是采用回写策略。**

处理器不能自动同步它们自己的TLB高速缓存，因为决定线性地址空间和物理地址之间映射何时不再有效的是内核而不是硬件，当页表发生变化时，内核必须刷新与相应线性地址对应的任何本地TLB表项。

内核在下列情况下将避免TLB被刷新：
1. 当两个使用相同页表集的普通进程之间执行进程切换时。
2. 当在一个普通进程和一个内核线程间执行进程切换时，事实上，内核线程并不拥有自己的页表集；更确切的说，它们使用刚在CPU上执行过的普通进程的页表集。

linux2.6提供了几种TLB刷新方法。某些情况下，多个CPU正在使用相同的页表（比如多线程），而此时页表项发生了改变，那么内核必须刷新这些CPU上与相应线性地址对应的TLB表项。为了避免多处理器系统上无用的TLB刷新，内核使用一种叫做**懒惰TLB（lazy TLB）模式**的技术，其基本思想是：如果几个CPU正在使用相同的页表，而且必须对这些CPU上的一个TLB表项刷新，那么，在某些情况下，正在运行内核线程的那些CPU上的刷新就可以延迟。当某个CPU开始运行一个内核线程时，内核把它置为懒惰TLB模式。当发出清除TLB表项的请求时，处于懒惰TLB模式的每个CPU都不刷新相应的表项。只要处于懒惰TLB模式的CPU用一个不同的页表集切换到一个普通进程，硬件就自动刷新TLB表项。同时内核把CPU设置为非懒惰TLB模式。然而，如果处于懒惰TLB模式的CPU切换到的进程与刚才运行的内核线程拥有同样的页表集，那么，任何使TLB无效的延迟操作必须由内核有效的实施。

当发生进程切换时，linux把 cr3 控制寄存器的内容保存在前一个进程的描述符中，然后把下一个要执行进程的描述符的值装入 cr3 寄存器中。因此，当新进程重新开始在CPU上执行时，分页单元指向一组正确的页表。

linux提供了大量宏来处理线性地址、页表和页表项。

PAGE_OFFSET表示线性地址空间中用户态地址和内核态地址的分界线（32位下为0xc0000000）



#### linux的内核页表 ####

内核维持着一组自己使用的页表，驻留在所谓的主内核页全局目录中，主内核页全局目录的最高目录项部分作为参考模型，为系统中每个普通进程对应的页全局目录提供参考模型。每个进程的“进程页表”中的内核态地址相关的页表项都是“内核页表”中的一份拷贝（所有进程的内核态线性地址区间共享）。内核启动时，会将RAM中物理地址前 896MB 的页框映射到内核线性地址空间从 PAGE_OFFSET 开始的896MB线性地址区间。



********************************************
### Part 2 : 内存管理###

内核的内存管理主要包括两个部分：内核的线性地址空间中的内存分配和对于所有进程都具有意义的页框管理。

由于linux支持非一致内存访问模型（Non-Uniform Memory Access，NUMA）模型，在这种模型中，给定CPU对于不同内存单元的访问时间可能不一样。系统的物理内存被划分为几个节点（node）。在一个单独的节点内，任一给定CPU访问页面所需的时间都是相同的。然而，对于不同的CPU，这个时间可能就不同。对每个CPU而言，内核都试图把耗时节点的访问次数减到最少，这就要小心地选择CPU最常引用的内核数据结构的存放位置。

linux内核中用节点描述符（类型为 pg\_data\_t）来描述一个节点。所有节点的描述符存放在一个单向链表中，它的第一个元素由 pgdat_list 变量指向。

由于我们只关注x86体系结构，而IBM兼容PC使用一致内存访问（UMA）模型，因此并不真正需要NUMA的支持。然而，即使NUMA的支持没有编译进内核，linux还是使用节点，不过，在UMA中只有一个单独的节点，它包含了系统中所含有的所有物理内存。因此，pgdat_list 变量指向一个只有一个元素的链表，这个元素就是节点0描述符，它被存放在 contig\_page\_data 变量中。



#### 页框管理 ####

由于实际的计算机体系结构有硬件的制约，这限制了页框可以使用的方式。尤其是，linux内核必须处理x86体系结构的两种硬件约束：
1. ISA总线的直接内存访问（DMA）处理器有一个严格的限制，它们只能对RAM的前16MB寻址。
2. 在具有大容量RAM的现代32位计算机中，CPU不能直接访问所有物理内存，因为线性地址空间太小。

为了应对这两种限制，linux2.6把每个内存节点的物理内存划分为3个管理区。在80x86 UMA 体系结构中的管理区为：

&emsp;&emsp;ZONE\_DMA：包含低于16MB的内存页框

&emsp;&emsp;ZONE\_NORMAL：包含高于16MB且低于896MB的内存页框

&emsp;&emsp;ZONE\_HIGHMEM：包含从896MB开始高于896MB的内存页框

ZONE\_DMA 区包含的页框可以由老式基于ISA的设备通过DMA使用。ZONE\_DMA 和 ZONE\_NORMAL 区包含内存的“常规”页框，内核启动时通过把它们线性地映射到线性地址空间的第4个GB，在之后直接进行访问。ZONE\_HIGHMEM 区包含的内存页不能由内核直接访问（这些页框大多数被分配给用户进程），尽管它们也能线性地映射到线性地址空间的第4个GB。在64位体系结构上 ZONE\_HIGHMEM 区总是空的。

内核使用页描述符（类型为 page）来记录每个页框的状态，所有的页描述符存放在 mem\_map 数组中。因为每个描述符长度为32字节，所以 mem\_map 所需要的空间略小于整个RAM的1%。virt\_to\_page(addr) 宏产生线性地址 addr 对应的页描述符地址。pfn\_to\_page(pfn) 宏产生与页框号 pfn 对应的页描述符地址。

还有个section的概念（类型为 mem_section）也用来组织页框，用来防止为空洞区域建立 page 结构造成空间浪费，保证尽量只为有效区域中的页框建立 page 结构。（书上没有讲，在源码中 /include/linux/mmzone.h 有定义，貌似跟 zone 没关系）

管理区描述符被用来描述管理区，每个页描述符都有到内存节点和到节点内管理区（包含相应页框）的链接。为节省空间，这些链接的存放方式与普通指针不同，而是被编码成索引存放在页描述符 flags 字段的高位。实际上，刻画页框的标志的数目是有限的，因此保留 flags 字段的最高位来编码特定内存节点和管理区号总是可能的。page_zone() 函数接收一个页描述符地址作为它的参数；它读取页描述符中 flags 字段的最高位，然后通过查看 zone_table 数组来确定相应管理区描述符的地址。在启动时用所有内存节点的所有管理区描述符的地址初始化这个数组。

当内核调用一个内存分配函数时，必须指明请求页框所在的管理区。内核通常指明它愿意使用哪个管理区。为了在内存分配请求中指定首选管理区，内核使用 zonelist 数据结构，这就是管理区描述符指针数组。

请求页框有两种方式：原子的和非原子的，对于非原子（一般）的页框请求，如果有足够的页框可用，请求就会被立刻满足。否则，必须回收一些内存，并且将发出请求的内核控制路径阻塞，直到有内存被释放。但是一些内核控制路径不能被阻塞（比如说在处理中断或在执行临界区内的代码时），在这些情况下，一条内核控制路径应当产生原子的页框分配请求。原子页框分配请求从不被阻塞；如果没有足够的空闲页框，则仅仅是分配失败而已。

**保留的页框池**：为了尽量减少一个原子页框分配请求的失败可能性，内核为原子页框分配请求保留了一个页框池，只有在内存不足才使用。保存内存的数量（以KB为单位）存放在 min\_free\_kbytes 变量中。它的初始值在内核初始化时设置，并取决于直接映射到内存线性地址空间第4个GB的物理内存的数量（也就是 ZONE\_DMA 和 ZONE\_NORMAL 的页框数目）。ZONE\_DMA 和 ZONE\_NORMAL 内存管理区将一定数量的页框贡献给保留内存，这个数目与两个管理区的大小成正比。管理区的 pages\_min 字段存储了管理区保留页框的数目，这个字段和 pages\_low、pages\_high 字段一起还在页框回收算法中起作用。pages\_low 字段总是被设为 pages\_min 的值的5/4，而 pages\_high 总是被设为 pages\_min 的值的3/2。

被称作**分区页框分配器（zoned page frame allocator）**的内核子系统负责处理对连续页框组的内存分配请求。分区页框分配器由 **管理区分配器**、**每CPU页高速缓存**和**伙伴系统** 组成。其中，每个管理区包含一个每CPU页高数缓存和一个伙伴系统。管理区分配器作为内核页框分配器的前端，该构件通过向每个管理区的每CPU页高速缓存请求一组连续页框来满足请求。而每CPU页高速缓存包含一些预先分配的页框，它们用于满足本地CPU发出的单一内存请求。如果请求的是一组连续的页框，则每CPU页高速缓存会从伙伴系统中分配请求所需要的页框。

可以通过6个稍有差别的函数和宏请求页框，除非另作说明，一般情况下，它们都返回第一个所分配页的线性地址，或者分配失败，则返回NULL：

```c
// 用这个函数请求2的order次方个连续的页框。它返回第一个所分配页框描述符的地址，失败返回NULL
static inline struct page *
alloc_pages(unsigned int gfp_mask, unsigned int order)
  
// 请求一个单独页框的宏
#define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)
  
// 该函数类似于alloc_pages()，但它返回第一个所分配的页的线性地址
fastcall unsigned long __get_free_pages(unsigned int gfp_mask, unsigned int order)
  
// 获得一个单独页框的宏
#define __get_free_page(gfp_mask) \
		__get_free_pages((gfp_mask),0)

// 该函数用来获得填满0的页框
fastcall unsigned long get_zeroed_page(unsigned int gfp_mask)
{
	struct page * page;

	/*
	 * get_zeroed_page() returns a 32-bit address, which cannot represent
	 * a highmem page
	 */
	BUG_ON(gfp_mask & __GFP_HIGHMEM);

	page = alloc_pages(gfp_mask | __GFP_ZERO, 0);  // 调用alloc_pages()
	if (page)
		return (unsigned long) page_address(page);
	return 0;
}

// 用这个宏获得适用于DMA的页框
#define __get_dma_pages(gfp_mask, order) \
		__get_free_pages((gfp_mask) | GFP_DMA,(order))
```

其中参数 gfp\_mask 是一组标志，它指明了如何寻找空闲的页框。其中的 \_\_GFP\_DMA 和 \_\_HIGHMEM 标志被称作管理区修饰符；它们标示寻找空闲页框内核所搜索的管理区。contig\_page\_data 节点描述符的 node\_zonelists 字段（zonelist 数组类型）是一个管理区描述符链表的数组，它代表后备管理区：对管理区修饰符的每一个设置，相应的链表包含的内存管理区能在原来的管理区缺少页框的情况下被用于满足内存分配请求。在 x86 UMA 体系结构中，后备管理区如下：

* 如果 \_\_GFP\_DMA 标志被设置，则只能从 ZONE\_DMA 内存管理区中获取页框。
* 否则，如果 \_\_GFP_HIGHMEN 标志没有被置位，则只能按优先次序从 ZONE\_NORMAL 和 ZONE_DMA 内存管理区获得页框。
* 否则（\_\_GFP\_HIGHMEN 标志被置位），则可以按优先次序从 ZONE\_HIGHMEM、ZONE\_NORMAL 和 ZONE\_DMA 内存管理区获得页框。


下面4个函数和宏中的任一个都可以释放页框：

```c

```






#### 伙伴系统 ####

在页框分配中，存在一个著名的内存管理问题，也就是作为的**外碎片（external fragmentation）**。频繁地请求和释放不同大小的一组连续页框，必然会导致在已分配页框的块内分散了许多小块的空闲页框，由此带来的问题是，即使有足够的空闲页框可以满足请求，但要分配一个大块的连续页框可能无法满足。从本质上说，有两种方法避免外碎片的方法：1、利用分页单元把一组非连续的的空闲页框映射到连续的线性地址空间  2、用一种方式记录现存的空闲连续页框的情况，尽量避免为满足对小块的请求而分割大的空闲块。

基于以下三种原因，linux选择第二种方法：

1. 在某些情况下，连续的页框确实是必要的，因为连续的线性地址并不足以满足请求。一个典型的例子就是给DMA处理器分配缓冲区的内存请求。因为当在一次单独的I/O操作中传送几个磁盘扇区的数据时，DMA忽略分页单元而直接访问地址总线，因此，所请求的缓冲区就必须位于连续的页框中。
2. 相比与第一中方法，第二种方法可以尽量使页表保持不变。频繁地修改页表势必导致平均访问内存次数增加，因为这会使CPU频繁地刷新TLB的内容，导致寻址效率大大降低。
3. 内核可以通过4MB的页访问大块连续的物理内存。这样减少了TLB的失效率，提高了访问内存的平均速度。

linux采用著名的**伙伴系统（buddy system）算法**来解决外碎片的问题。

内核为每个管理区使用不同的伙伴系统。在每个管理区描述符中存在一个 zone\_mem\_map 字段，它是一个指向 mem\_map 数组中该管理区第一个页框的页描述符的指针，管理区描述符中的另一个字段 size 表示了管理区中页框的数量（每个管理区都是 mem\_map 数组的一个子集）。管理区描述符中的 free\_area 字段是一个包含有11个元素，元素类型为 free\_area 的数组，它是伙伴系统的关键数据结构。

伙伴系统将所有的空闲页框分组为11个块链表，每个块链表分别包含大小为 1、2、4、８、16、32、64、128、256、512和1024（$ 2^0$~ $ 2^{10} $）个连续的页框（分别对应管理区描述符 free_area 字段中的索引为0~10的元素）。对1024个页框的最大请求对应着4MB大小的连续RAM块。每个块的第一个页框的物理地址是该块大小的整数倍。

（这里要注意，在系统中，需要向伙伴系统申请页框时，页框的数量都是以2的次方请求的）当请求一个 $ 2^n $ 大小的块时，算法会先查看 free\_area 数组中索引为n的元素是否为空，它标识大小为 $ 2^n $ 的空闲块。（元素为 free\_area结构，其 free\_list 字段是双向循环链表的头，这个双向循环链表包含了管理区中每个大小为 $ 2^n $ 页框的空闲块的起始页框的页描述符，指向链表中相邻元素的指针存放在页描述符的 lru 字段中。元素中的 nr\_free 字段指定了大小为 $ 2^n $ 页框的空闲块的个数）如果元素不为空，则可以直接满足要求。如果元素为空，那么算法会查找下一个更大的空闲块，也就是在 $ 2^{n+1} $ 页框块的链表中查找一个空闲块。如果存在一个这样的块，内核就把 $ 2^{n+1} $ 的块分成两等份，一半用作满足请求，另一半插入大小为 $ 2^n $ 页框的空闲块链表中。如果在 $ 2^{n+1} $ 个页框的块链表中也没有找到空闲块，就继续找更大的块—— $ 2^{n+2} $ 个页框的块。如果这样的块存在，内核把 $ 2^{n+2} $ 个页框块中的  $ 2^{n} $ 个页框用来满足请求，然后从剩余 $ 2^{n+1} + 2^{n} $ 个页框中拿  $ 2^{n+1} $ 个插入到索引为 n+1 的元素的链表中，再把最后  $ 2^{n} $ 个页框插入到索引为n的元素的链表中。

以上过程的逆过程就是页框块的释放过程，也是该算法名字的由来。内核试图把大小为 $ 2^{n} $ 的一对空闲伙伴块合并为一个大小为 $ 2^{n+1} $ 的单独块。满足以下条件的两个块称为伙伴：

* 两个块具有相同的大小，记为 $ 2^{n} $ 
* 它们的物理地址是连续的。
* 第一块的第一个页框的物理地址是 $2*2^{n}*2^{12} $ 的倍数。（ $ 2^{12} $ 为4KB大小）

该算法是**迭代**的，如果它成功合并所释放的块，它会试图合并 $ 2^{n+1} $ 的块，以再次试图形成更大的块。每个空闲块的起始页框的页描述符中的 private 字段存放了块的大小 order （表示块大小为 $ 2^{order} $)。当空闲块被释放时，内核首先计算块中第一个页框的下标 page\_idx，这是相对于管理区中的第一个页框而言的。局部变量 order 表示块的大小的对数，order\_size 表示块的大小（都以页框为单位）。被释放的空闲块对应的伙伴的索引 buddy\_idx 可以用以下公式计算得到：

```c
buddy_idx = page_idx ^ (1 << order);
```

该公式使用（1<<order）掩码的异或（XOR）转换 page_idx 第 order 位的值。因此，如果这个位原先是0，buddy_idx 就等于 page\_idx + order\_size（当前释放的块位于buddy的前面）；相反如果这个位原先是1，buddy_idx 就等于 page\_idx - order\_size（当前释放的块位于buddy的后面）。一旦知道了伙伴块的下标，就可以很容易地得到伙伴块的页描述符。然后通过查看该页描述符是否空闲（\_count 字段必须为-1）、是否属于动态内存（flags 字段的 PG\_reserved 是否清零）、flags 字段的 PG_private 是否置位（表示private字段是否有意义）和 private 字段的值是否等于 order 来判断能否合并。如果满足条件，会递增 order 并进行下一次循环尝试合并。如果有一个条件不满足，则该函数跳出循环并将其插入适当的空闲块链表，并更新第一个页框描述符的 private 字段（可能已经合并过）。

伙伴系统的操作主要由两个函数进行：

```C
// 分配一个块，接收两个参数：管理区描述符的地址和空闲块大小的对数值order
// 成功返回第一个被分配页框的页描述符地址，失败返回NULL
static struct page *__rmqueue(struct zone *zone, unsigned int order) 

// 释放页框
// 2.6.11内核中，之后被替换掉
// page为被释放块中所包含的第一个页框的描述符的地址，zone为管理区描述符的地址，order为块大小的对数
// base为管理区第一个页框的描述符的地址
static inline void __free_pages_bulk (struct page *page, struct page *base,
		struct zone *zone, unsigned int order)
```



#### 每CPU页框高速缓存 #### 

内核经常请求和释放单个页框为了提升系统性能（如果每次都从伙伴系统中请求和释放页框，可能需要一些额外的操作），每个内存管理区分配了定义了一个“每CPU”页框高速缓存。所有“每CPU”高速缓存包括一些预先分配的页框，它们被用于满足本地CPU发出的单一页框请求。

实际上，这里为每个内存管理区和每个CPU提供了两个高速缓存：一个**热高速缓存**，它存放的页框中所包含的内容很可能就在CPU硬件高速缓存中；还有一个**冷高速缓存**。如果内核或用户态进程在刚分配到页框后就立即向页框写，那么从热高速缓存中获得页框就对系统性能有利。反过来，如果页框将要被DMA操作填充，那么从冷高速缓存中获得页框是方便的。在这种情况下，不会涉及到CPU，并且硬件高速缓存的行不会被修改。从冷高速缓存获得的页框为其他类型的内存分配保存了热页框储备。

实现每CPU页框高速缓存的主要数据结构是存放在内存管理区描述符的 pageset 字段中的一个 per\_cpu\_pageset 数组数据结构。该数组包含为每个CPU提供的一个元素；这个元素依次由两个 per_cpu_pages 描述符组成，一个留给热高速缓存而另一个留给冷高速缓存。内核使用 per\_cpu\_pages 结构中的两个位标（int类型）来监视热高速缓存和冷高速缓存的大小：如果页框个数低于下界 low（字段），内核通过从伙伴系统中分配 batch（也存在于 per_cpu_pages 结构中，int类型）个单一页框来补充对应的高速缓存；否则，如果页框个数高过上界 high（字段），内核从高速缓存中释放 batch 个页框到伙伴系统中。值 batch、low 和 high 本质上取决于内存管理区中包含的页框个数。

每CPU高速缓存相关的接口主要有下面几个：

```c
// 在指定的内存管理区中分配页框
// 它使用每CPU高速缓存来处理单一页框请求
// zone为制定的内存管理区描述符地址，order为请求页框大小的对数，gfp_flags为分配标志，分配标志中如果
// __GFP_COLD被置位，页框从冷高速缓存中获取，否则它从热高速缓存中获取（该标志只对单一页框请求有意义）
// 这个函数2.6.11内核里有，在4.x内核中就被修改掉了。。。
static struct page *
buffered_rmqueue(struct zone *zone, int order, int gfp_flags)

// 这两个也是只在2.6.11左右内核里有，之后被去掉了
// 都是free_hot_cold_page()函数的简单封装，用来释放单个页框到每CPU高速缓存
void fastcall free_hot_page(struct page *page)
{
	free_hot_cold_page(page, 0);
}
	
void fastcall free_cold_page(struct page *page)
{
	free_hot_cold_page(page, 1);
}

// page 为将要释放的页框的页描述符地址，cold为标志
// 调用free_pages_bulk() 函数
static void fastcall free_hot_cold_page(struct page *page, int cold)
  

static int
free_pages_bulk(struct zone *zone, int count,
		struct list_head *list, unsigned int order)
```

buffered\_rmqueue() 首先检查 order 是否等于0，如果不等于0，则调用 \_\_rmqueue() 函数从伙伴系统中分配所请求的页框满足请求。如果order等于0，则检查由 \_\_GFP\_COLD 标志所指示的内存管理区本地每CPU高速缓存是否需要补充（per\_cpu_pages 描述符的 count 字段或等于 low 字段），如果需要补充，则反复调用 \_\_rmqueue() 函数从伙伴系统中分配 batch 个单一页框插入 per\_cpu\_pages 描述符的 list 字段对应的高速缓存链表，然后更新 count 字段；之后如果 count 字段为正（每CPU高速缓存可能为空，\_\_rmqueue() 调用可能失败），则从高速缓存链表中获得一个页框，count减1；如果内存请求还没被满足，调用 \_\_rmqueue() 函数从伙伴系统中分配所请求的页框。

如果请求得到满足，函数就初始化（第一个）页框的页描述符：清除一些标志，将 private 字段置0，并将页框引用计数器置1。此外，如果 gfp_flags 中的 \_\_GPF\_\_ZERO 标志被置位，则函数将被分配的内存区填充0。然后返回（第一个）页框的页描述符地址，如果页框分配请求失败返回NULL。

释放单个页框的主要操作是 free\_hot\_cold\_page() 函数。它首先从 page->flags 字段获取包含该页框的内存管理区描述符地址，然后获取由 cold 标志选择的管理区高速缓存的 per\_cpu\_pages 描述符的地址。之后检查是否需要清空高速缓存（count 字段是否高于或等于 high 字段）。如果需要，则调用 free\_pages\_bulk() 函数，将管理区描述符，将被释放的页框个数（batch 字段）、高速缓存链表的地址以及数字0（为0到order个页框）传递给该函数。free\_pages\_bulk() 函数依次反复调用 \_\_free\_pages\_bulk() 函数来释放指定数量的（从高速缓存链表中获得的）页框到内存管理区的伙伴系统中。然后将 page（要释放的页框）添加到高速缓存链表上，更新 count 字段。

在linux2.6内核（早期？）版本中，从没有页框被释放到冷高速缓存中：至于硬件高速缓存，内核总是假设被释放的页框是热的。当然，这并不意味着冷高速缓存是空的：当达到下界时通过 buffered\_rmqueue() 补充冷高速缓存。



#### 管理区分配器 ####

管理区分配器是内核页框分配器的前端，该构件必须分配一个包含足够多空闲页框的内存区，使它能满足内存请求。管理区分配器必须满足几个目标：

* 它应当保护保留的页框池
* 当内存不足且允许阻塞当前进程时，它应当触发页框回收算法；一旦某些页框被释放，管理区分配器将再次尝试分配。
* 如果可能，它应当保存小而珍贵的 ZONE_DMA 内存管理区。例如，如果是对 ZONE\_NORMAL 或 ZONE\_HIGNMEM 页框的请求，那么管理区分配器会不太愿意分配 ZONE\_DMA 内存管理区中的页框。

